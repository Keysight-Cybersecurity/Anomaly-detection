{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5916af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedNASInvalidMessageDetector:\n",
    "    def __init__(self):\n",
    "        # ML components\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = {\n",
    "            'isolation_forest': IsolationForest(contamination=0.01, random_state=42),\n",
    "            'one_class_svm': OneClassSVM(nu=0.01, kernel='rbf', gamma='auto')\n",
    "        }\n",
    "        self.trained_models = {}\n",
    "        self.feature_columns = None\n",
    "        self.contamination_rate = 0.01\n",
    "        # Adjust weights to rely more on Isolation Forest\n",
    "        self.ensemble_weights = {'isolation_forest': 0.8, 'one_class_svm': 0.2}  \n",
    "        self.optimal_threshold = None\n",
    "        \n",
    "        # Confidence thresholds for reducing false positives\n",
    "        self.confidence_threshold = 0.8\n",
    "        self.rule_based_weight = 0.7  # Increased weight for rules\n",
    "        self.ml_based_weight = 0.3   # Decreased weight for ML\n",
    "        \n",
    "        # Valid 5GMM message types\n",
    "        self.valid_5gmm_types = {\n",
    "            '65': 'RegistrationRequest',\n",
    "            '66': 'RegistrationAccept',\n",
    "            '67': 'RegistrationComplete',\n",
    "            '68': 'RegistrationReject',\n",
    "            '69': 'DeregistrationRequestUE',\n",
    "            '70': 'DeregistrationAcceptUE',\n",
    "            '71': 'DeregistrationRequestAMF',\n",
    "            '72': 'DeregistrationAcceptAMF',\n",
    "            '76': 'ServiceRequest',\n",
    "            '77': 'ServiceReject',\n",
    "            '78': 'ServiceAccept',\n",
    "            '79': 'ControlPlaneServiceRequest',\n",
    "            '80': 'NetworkSliceSpecificAuthenticationCommand',\n",
    "            '81': 'NetworkSliceSpecificAuthenticationComplete',\n",
    "            '82': 'NetworkSliceSpecificAuthenticationResult',\n",
    "            '84': 'ConfigurationUpdateCommand',\n",
    "            '85': 'ConfigurationUpdateComplete',\n",
    "            '86': 'AuthenticationRequest',\n",
    "            '87': 'AuthenticationResponse',\n",
    "            '88': 'AuthenticationReject',\n",
    "            '89': 'AuthenticationFailure',\n",
    "            '90': 'AuthenticationResult',\n",
    "            '91': 'IdentityRequest',\n",
    "            '92': 'IdentityResponse',\n",
    "            '93': 'SecurityModeCommand',\n",
    "            '94': 'SecurityModeComplete',\n",
    "            '95': 'SecurityModeReject',\n",
    "            '100': 'Status',\n",
    "            '101': 'Notification',\n",
    "            '102': 'NotificationResponse',\n",
    "            '103': 'ULNASTransport',\n",
    "            '104': 'DLNASTransport'\n",
    "        }\n",
    "        \n",
    "        self.session_states = defaultdict(lambda: {'state': 'IDLE', 'security_activated': False})\n",
    "        \n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"Convert string data to proper types\"\"\"\n",
    "        df = df.copy()\n",
    "        numeric_cols = ['Time', 'AMF_UE_NGAP_ID', 'procedureCode', 'Type', 'Seqn', 'SecHdr', 'EPD', 'spare']\n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        return df\n",
    "    \n",
    "    def validate_nas_message(self, row):\n",
    "        \"\"\"Validate individual NAS message against protocol rules\"\"\"\n",
    "        violations = []\n",
    "        violation_severity = []  # Track severity of violations\n",
    "        \n",
    "        # Check message type validity\n",
    "        msg_type = str(int(row['Type'])) if not pd.isna(row['Type']) else None\n",
    "        if msg_type and msg_type not in self.valid_5gmm_types:\n",
    "            violations.append(f\"Invalid message type: {msg_type}\")\n",
    "            violation_severity.append(3)  # High severity\n",
    "        \n",
    "        # Check EPD (should be 126 for 5GMM)\n",
    "        if not pd.isna(row['EPD']) and int(row['EPD']) != 126:\n",
    "            violations.append(f\"Invalid EPD: {int(row['EPD'])}\")\n",
    "            violation_severity.append(2)  # Medium severity\n",
    "        \n",
    "        # Check security header constraints\n",
    "        sec_hdr = row['SecHdr'] if not pd.isna(row['SecHdr']) else None\n",
    "        if sec_hdr is not None:\n",
    "            if sec_hdr < 0 or sec_hdr > 5:\n",
    "                violations.append(f\"Invalid security header: {int(sec_hdr)}\")\n",
    "                violation_severity.append(3)  # High severity\n",
    "        \n",
    "        # Check sequence number validity\n",
    "        seq_num = row['Seqn'] if not pd.isna(row['Seqn']) else None\n",
    "        if seq_num is not None and (seq_num < 0 or seq_num > 255):\n",
    "            violations.append(f\"Invalid sequence number: {seq_num}\")\n",
    "            violation_severity.append(1)  # Low severity\n",
    "        \n",
    "        # Check spare field (should be 0)\n",
    "        spare = row['spare'] if not pd.isna(row['spare']) else None\n",
    "        if spare is not None and int(spare) != 0:\n",
    "            violations.append(f\"Invalid spare field: {int(spare)}\")\n",
    "            violation_severity.append(1)  # Low severity\n",
    "        \n",
    "        # Calculate total severity score\n",
    "        total_severity = sum(violation_severity) if violation_severity else 0\n",
    "        \n",
    "        return violations, total_severity\n",
    "    \n",
    "    def engineer_features_enhanced(self, df):\n",
    "        \"\"\"Enhanced feature engineering for invalid message detection\"\"\"\n",
    "        # Filter NAS messages\n",
    "        nas_df = df.copy()\n",
    "        nas_df = nas_df.sort_values('Time').reset_index(drop=True)\n",
    "        \n",
    "        features = pd.DataFrame()\n",
    "        \n",
    "        # Basic features\n",
    "        features['time'] = nas_df['Time']\n",
    "        features['session_id'] = nas_df['AMF_UE_NGAP_ID']\n",
    "        features['msg_type'] = nas_df['Type'].fillna(-1)\n",
    "        features['proc_code'] = nas_df['procedureCode'].fillna(-1)\n",
    "        features['sequence'] = nas_df['Seqn'].fillna(-1)\n",
    "        features['sec_hdr'] = nas_df['SecHdr'].fillna(-1)\n",
    "        features['epd'] = nas_df['EPD'].fillna(-1)\n",
    "        features['spare'] = nas_df['spare'].fillna(-1)\n",
    "        \n",
    "        # Invalid message type indicator\n",
    "        features['is_valid_msg_type'] = features['msg_type'].astype(str).isin(self.valid_5gmm_types.keys()).astype(int)\n",
    "        features['is_valid_epd'] = (features['epd'] == 126).astype(int)\n",
    "        features['is_valid_sec_hdr'] = ((features['sec_hdr'] >= 0) & (features['sec_hdr'] <= 5)).astype(int)\n",
    "        features['is_valid_seq'] = ((features['sequence'] >= 0) & (features['sequence'] <= 255)).astype(int)\n",
    "        features['is_valid_spare'] = (features['spare'] == 0).astype(int)\n",
    "        \n",
    "        # Add severity scores for each message\n",
    "        severity_scores = []\n",
    "        for idx, row in nas_df.iterrows():\n",
    "            _, severity = self.validate_nas_message(row)\n",
    "            severity_scores.append(severity)\n",
    "        features['severity_score'] = severity_scores\n",
    "        \n",
    "        # Protocol state features\n",
    "        for session_id in features['session_id'].unique():\n",
    "            mask = features['session_id'] == session_id\n",
    "            session_data = features[mask]\n",
    "            \n",
    "            # Time-based features\n",
    "            features.loc[mask, 'time_diff'] = session_data['time'].diff().fillna(0)\n",
    "            features.loc[mask, 'time_since_start'] = session_data['time'] - session_data['time'].min()\n",
    "            \n",
    "            # Message sequence analysis\n",
    "            features.loc[mask, 'msg_position'] = range(1, len(session_data) + 1)\n",
    "            features.loc[mask, 'msg_rate'] = features.loc[mask, 'msg_position'] / (features.loc[mask, 'time_since_start'] + 0.001)\n",
    "            \n",
    "            # Protocol flow validation\n",
    "            prev_msg_type = -1\n",
    "            for idx in session_data.index:\n",
    "                curr_msg_type = features.loc[idx, 'msg_type']\n",
    "                features.loc[idx, 'valid_sequence'] = self.is_valid_message_sequence(prev_msg_type, curr_msg_type)\n",
    "                prev_msg_type = curr_msg_type\n",
    "            \n",
    "            # Security context validation\n",
    "            security_active = False\n",
    "            for idx in session_data.index:\n",
    "                msg_type = features.loc[idx, 'msg_type']\n",
    "                sec_hdr = features.loc[idx, 'sec_hdr']\n",
    "                \n",
    "                if msg_type == 94:  # SecurityModeComplete\n",
    "                    security_active = True\n",
    "                \n",
    "                if security_active and sec_hdr in [0, -1]:\n",
    "                    features.loc[idx, 'security_violation'] = 1\n",
    "                else:\n",
    "                    features.loc[idx, 'security_violation'] = 0\n",
    "        \n",
    "        # Anomaly score based on validity checks\n",
    "        features['validity_score'] = (\n",
    "            features['is_valid_msg_type'] + \n",
    "            features['is_valid_epd'] + \n",
    "            features['is_valid_sec_hdr'] + \n",
    "            features['is_valid_seq'] +\n",
    "            features['is_valid_spare']\n",
    "        ) / 5.0\n",
    "        \n",
    "        # Weighted invalid risk score with emphasis on high-severity violations\n",
    "        features['invalid_risk_score'] = (\n",
    "            (1 - features['is_valid_msg_type']) * 5 +  # Increased weight\n",
    "            (1 - features['is_valid_epd']) * 3 +      # Increased weight\n",
    "            (1 - features['is_valid_sec_hdr']) * 4 +  # Increased weight\n",
    "            (1 - features['is_valid_seq']) * 0.5 +    # Reduced weight\n",
    "            (1 - features['is_valid_spare']) * 0.5 +  # Reduced weight\n",
    "            features['security_violation'] * 2 +\n",
    "            features['severity_score'] * 0.5  # Add severity score\n",
    "        )\n",
    "        \n",
    "        # Statistical features\n",
    "        features['msg_type_frequency'] = features.groupby(['session_id', 'msg_type'])['msg_type'].transform('count')\n",
    "        features['unusual_msg_type'] = (features['msg_type_frequency'] == 1).astype(int)\n",
    "        \n",
    "        # Add confidence features\n",
    "        features['confidence_score'] = 1.0 - (features['invalid_risk_score'] / features['invalid_risk_score'].max())\n",
    "        \n",
    "        # Normalize features to reduce SVM sensitivity\n",
    "        numeric_features = ['time_diff', 'time_since_start', 'msg_rate', 'msg_position']\n",
    "        for feat in numeric_features:\n",
    "            if feat in features.columns:\n",
    "                mean_val = features[feat].mean()\n",
    "                std_val = features[feat].std()\n",
    "                if std_val > 0:\n",
    "                    features[f'{feat}_normalized'] = (features[feat] - mean_val) / std_val\n",
    "                else:\n",
    "                    features[f'{feat}_normalized'] = 0\n",
    "        \n",
    "        features = features.fillna(0)\n",
    "        \n",
    "        return features, nas_df\n",
    "    \n",
    "    def is_valid_message_sequence(self, prev_type, curr_type):\n",
    "        \"\"\"Check if message sequence is valid according to 5GMM protocol\"\"\"\n",
    "        prev_str = str(int(prev_type)) if prev_type != -1 else None\n",
    "        curr_str = str(int(curr_type)) if curr_type != -1 else None\n",
    "        \n",
    "        # Define valid message sequences (simplified)\n",
    "        valid_sequences = {\n",
    "            '65': ['66', '68', '86', '91'],  # After RegistrationRequest\n",
    "            '86': ['87', '89'],  # After AuthenticationRequest\n",
    "            '87': ['90', '88'],  # After AuthenticationResponse\n",
    "            '93': ['94', '95'],  # After SecurityModeCommand\n",
    "            '94': ['66'],  # After SecurityModeComplete\n",
    "        }\n",
    "        \n",
    "        if prev_str is None or prev_str not in valid_sequences:\n",
    "            return 1  # Consider valid if no specific rule\n",
    "        \n",
    "        return 1 if curr_str in valid_sequences.get(prev_str, []) else 0\n",
    "    \n",
    "    def detect_invalid_messages(self, df):\n",
    "        \"\"\"Detect invalid NAS messages based on protocol rules\"\"\"\n",
    "        df = self.preprocess_data(df)\n",
    "        df = df.sort_values('Time').reset_index(drop=True)\n",
    "        \n",
    "        invalid_messages = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            violations, severity = self.validate_nas_message(row)\n",
    "            \n",
    "            # Include ALL violations for ground truth (no severity filtering)\n",
    "            if violations:\n",
    "                invalid_messages.append({\n",
    "                    'index': idx,\n",
    "                    'time': row['Time'],\n",
    "                    'session_id': row['AMF_UE_NGAP_ID'],\n",
    "                    'msg_type': row['Type'],\n",
    "                    'proc_code': row['procedureCode'],\n",
    "                    'violations': violations,\n",
    "                    'violation_count': len(violations),\n",
    "                    'severity': severity\n",
    "                })\n",
    "        \n",
    "        return invalid_messages\n",
    "    \n",
    "    def optimize_hyperparameters(self, X_train, features_df):\n",
    "        \"\"\"Optimize model hyperparameters with strong focus on reducing false positives\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"HYPERPARAMETER OPTIMIZATION\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        best_params = {}\n",
    "        \n",
    "        # Get indices of actual anomalies based on severity\n",
    "        anomaly_indices = np.where(features_df['severity_score'] > 0)[0]\n",
    "        if len(anomaly_indices) == 0:\n",
    "            # If no anomalies in training, use moderate contamination\n",
    "            expected_contamination = 0.02  # CHANGED: Balanced value\n",
    "            print(\"No anomalies detected in training data, using moderate contamination rate\")\n",
    "        else:\n",
    "            expected_contamination = len(anomaly_indices) / len(X_train)\n",
    "        \n",
    "        # Ensure contamination is within valid range (0.0, 0.5]\n",
    "        expected_contamination = max(0.01, min(0.5, expected_contamination))\n",
    "        print(f\"Expected contamination rate from training data: {expected_contamination:.2%}\")\n",
    "        \n",
    "        # Isolation Forest optimization - balanced approach\n",
    "        # CHANGED: Moderate contamination values\n",
    "        contamination_values = [0.01, 0.02, 0.03, 0.04]\n",
    "        \n",
    "        iso_param_grid = {\n",
    "            'contamination': contamination_values,\n",
    "            'n_estimators': [100, 150],\n",
    "            'max_samples': ['auto', 0.9],\n",
    "            'max_features': [0.8, 1.0],\n",
    "            'bootstrap': [True]  # CHANGED: Back to True for better generalization\n",
    "        }\n",
    "        \n",
    "        print(\"\\nOptimizing Isolation Forest...\")\n",
    "        best_score = float('-inf')\n",
    "        best_iso_params = None\n",
    "        \n",
    "        for params in ParameterGrid(iso_param_grid):\n",
    "            model = IsolationForest(random_state=42, **params)\n",
    "            model.fit(X_train)\n",
    "            \n",
    "            scores = model.score_samples(X_train)\n",
    "            predictions = model.predict(X_train)\n",
    "            \n",
    "            # Calculate false positive rate on training data\n",
    "            normal_indices = np.where(features_df['severity_score'] == 0)[0]\n",
    "            if len(normal_indices) > 0:\n",
    "                fp_rate = (predictions[normal_indices] == -1).sum() / len(normal_indices)\n",
    "            else:\n",
    "                fp_rate = 0\n",
    "            \n",
    "            # Balanced scoring\n",
    "            score_std = np.std(scores)\n",
    "            # Only moderate penalty for FP\n",
    "            combined_score = score_std - (fp_rate * 10)\n",
    "            \n",
    "            if combined_score > best_score:\n",
    "                best_score = combined_score\n",
    "                best_iso_params = params\n",
    "        \n",
    "        print(f\"Best Isolation Forest params: {best_iso_params}\")\n",
    "        best_params['isolation_forest'] = best_iso_params\n",
    "        \n",
    "        # One-Class SVM optimization - focusing on reducing false positives\n",
    "        # Train on a subset of normal data to reduce overfitting\n",
    "        normal_indices = np.where(features_df['severity_score'] == 0)[0]\n",
    "        if len(normal_indices) > 100:\n",
    "            # Use stratified sampling\n",
    "            train_size = int(0.8 * len(normal_indices))\n",
    "            train_indices = np.random.choice(normal_indices, train_size, replace=False)\n",
    "            X_train_svm = X_train[train_indices]\n",
    "        else:\n",
    "            X_train_svm = X_train\n",
    "        \n",
    "        # CHANGED: Very conservative nu values but with careful tuning\n",
    "        svm_param_grid = {\n",
    "            'nu': [0.001, 0.002, 0.003, 0.005],  # Very low nu\n",
    "            'kernel': ['rbf'],\n",
    "            'gamma': ['auto', 'scale'],  # Let sklearn choose optimal gamma\n",
    "            'tol': [0.001],\n",
    "            'shrinking': [True, False]  # ADDED: Can help with generalization\n",
    "        }\n",
    "        \n",
    "        print(\"\\nOptimizing One-Class SVM for minimal false positives...\")\n",
    "        best_score = float('-inf')\n",
    "        best_svm_params = None\n",
    "        best_fp_rate = 1.0\n",
    "        \n",
    "        for params in ParameterGrid(svm_param_grid):\n",
    "            try:\n",
    "                model = OneClassSVM(**params)\n",
    "                model.fit(X_train_svm)\n",
    "                \n",
    "                # Evaluate on full training set\n",
    "                predictions = model.predict(X_train)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                if len(normal_indices) > 0:\n",
    "                    fp_rate = (predictions[normal_indices] == -1).sum() / len(normal_indices)\n",
    "                else:\n",
    "                    fp_rate = 0\n",
    "                \n",
    "                # Extremely strict on false positives\n",
    "                if fp_rate < 0.02:  # Max 2% FP rate\n",
    "                    score = 1.0 - (fp_rate * 50)  # Heavy penalty\n",
    "                else:\n",
    "                    score = -fp_rate * 100\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_svm_params = params\n",
    "                    best_fp_rate = fp_rate\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        print(f\"Best One-Class SVM params: {best_svm_params}\")\n",
    "        print(f\"Best SVM FP rate: {best_fp_rate:.2%}\")\n",
    "        best_params['one_class_svm'] = best_svm_params\n",
    "        \n",
    "        # Update models with best parameters\n",
    "        self.models['isolation_forest'] = IsolationForest(random_state=42, **best_params['isolation_forest'])\n",
    "        self.models['one_class_svm'] = OneClassSVM(**best_params['one_class_svm'])\n",
    "        \n",
    "        self.contamination_rate = best_params['isolation_forest']['contamination']\n",
    "        \n",
    "        return best_params\n",
    "    \n",
    "    def ensemble_predict_with_confidence(self, X_test, features_df):\n",
    "        \"\"\"Enhanced ensemble prediction with improved detection\"\"\"\n",
    "        predictions = {}\n",
    "        scores = {}\n",
    "        \n",
    "        for model_name, model in self.trained_models.items():\n",
    "            predictions[model_name] = model.predict(X_test)\n",
    "            \n",
    "            if hasattr(model, 'decision_function'):\n",
    "                scores[model_name] = model.decision_function(X_test)\n",
    "            else:\n",
    "                scores[model_name] = model.score_samples(X_test)\n",
    "        \n",
    "        # Make predictions based on smart logic\n",
    "        ensemble_predictions = np.ones(len(X_test))\n",
    "        \n",
    "        # Decision logic that relies heavily on protocol violations\n",
    "        for i in range(len(X_test)):\n",
    "            iso_pred = predictions['isolation_forest'][i]\n",
    "            svm_pred = predictions['one_class_svm'][i]\n",
    "            severity = features_df['severity_score'].values[i]\n",
    "            \n",
    "            # CHANGED: Rule-based approach with ML support\n",
    "            # 1. Always flag high severity violations (EPD, message type)\n",
    "            if severity >= 2:\n",
    "                ensemble_predictions[i] = -1\n",
    "            # 2. For low severity, only flag if Isolation Forest agrees\n",
    "            # (ignore SVM due to high FP rate)\n",
    "            elif severity == 1 and iso_pred == -1:\n",
    "                ensemble_predictions[i] = -1\n",
    "            # 3. If no violation but BOTH models strongly agree, consider it\n",
    "            elif severity == 0 and iso_pred == -1 and svm_pred == -1:\n",
    "                # Double-check with score percentiles\n",
    "                iso_score = scores['isolation_forest'][i]\n",
    "                svm_score = scores['one_class_svm'][i]\n",
    "                iso_threshold = np.percentile(scores['isolation_forest'], 1)  # Very strict\n",
    "                svm_threshold = np.percentile(scores['one_class_svm'], 1)  # Very strict\n",
    "                \n",
    "                if iso_score < iso_threshold and svm_score < svm_threshold:\n",
    "                    ensemble_predictions[i] = -1\n",
    "        \n",
    "        # Calculate combined score for reporting\n",
    "        ml_score = np.zeros(len(X_test))\n",
    "        for model_name in self.ensemble_weights:\n",
    "            if model_name in scores:\n",
    "                normalized_score = (scores[model_name] - scores[model_name].min()) / \\\n",
    "                                 (scores[model_name].max() - scores[model_name].min() + 1e-10)\n",
    "                ml_score += normalized_score * self.ensemble_weights[model_name]\n",
    "        \n",
    "        rule_based_score = features_df['severity_score'].values / (features_df['severity_score'].max() + 0.001)\n",
    "        combined_score = (self.ml_based_weight * ml_score + self.rule_based_weight * rule_based_score)\n",
    "        \n",
    "        return ensemble_predictions, combined_score\n",
    "    \n",
    "    def train(self, train_data, optimize_params=True):\n",
    "        \"\"\"Train ML models on clean training data\"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"TRAINING PHASE - INVALID MESSAGE DETECTION\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        train_df = self.preprocess_data(train_data)\n",
    "        print(f\"Training data shape: {train_df.shape}\")\n",
    "        \n",
    "        features, nas_df = self.engineer_features_enhanced(train_df)\n",
    "        \n",
    "        print(f\"Training on {len(nas_df)} NAS messages\")\n",
    "        print(f\"Feature dimensions: {features.shape}\")\n",
    "        \n",
    "        self.feature_columns = features.columns.tolist()\n",
    "        X_train = self.scaler.fit_transform(features)\n",
    "        \n",
    "        # Optimize hyperparameters\n",
    "        if optimize_params:\n",
    "            best_params = self.optimize_hyperparameters(X_train, features)\n",
    "        \n",
    "        # Train models - CHANGED: Simplified training\n",
    "        for model_name, model in self.models.items():\n",
    "            print(f\"\\nTraining {model_name}...\")\n",
    "            model.fit(X_train)\n",
    "            self.trained_models[model_name] = model\n",
    "            \n",
    "            # Test on training data to check anomaly rate\n",
    "            predictions = model.predict(X_train)\n",
    "            anomaly_rate = (predictions == -1).sum() / len(predictions)\n",
    "            print(f\"  Training anomaly rate: {anomaly_rate:.2%}\")\n",
    "        \n",
    "        # CHANGED: More conservative ensemble weights\n",
    "        self.ensemble_weights = {'isolation_forest': 0.6, 'one_class_svm': 0.4}\n",
    "        self.rule_based_weight = 0.9  # CHANGED: Increased rule weight\n",
    "        self.ml_based_weight = 0.1   # CHANGED: Decreased ML weight\n",
    "        \n",
    "        print(\"\\nTraining complete!\")\n",
    "    \n",
    "    def optimize_ensemble_weights(self, X_train, features_df):\n",
    "        \"\"\"Optimize ensemble weights based on model performance\"\"\"\n",
    "        print(\"\\nOptimizing ensemble weights...\")\n",
    "        \n",
    "        scores = {}\n",
    "        predictions = {}\n",
    "        \n",
    "        for model_name, model in self.trained_models.items():\n",
    "            predictions[model_name] = model.predict(X_train)\n",
    "            if hasattr(model, 'decision_function'):\n",
    "                scores[model_name] = model.decision_function(X_train)\n",
    "            else:\n",
    "                scores[model_name] = model.score_samples(X_train)\n",
    "        \n",
    "        # Calculate false positive tendency for each model\n",
    "        # based on normal samples (severity_score == 0)\n",
    "        fp_rates = {}\n",
    "        detection_rates = {}\n",
    "        \n",
    "        normal_mask = features_df['severity_score'] == 0\n",
    "        anomaly_mask = features_df['severity_score'] > 0\n",
    "        \n",
    "        for model_name in predictions:\n",
    "            # False positive rate\n",
    "            if normal_mask.sum() > 0:\n",
    "                fp_rate = (predictions[model_name][normal_mask] == -1).sum() / normal_mask.sum()\n",
    "            else:\n",
    "                fp_rate = 0\n",
    "            fp_rates[model_name] = fp_rate\n",
    "            \n",
    "            # Detection rate\n",
    "            detection_rates[model_name] = (predictions[model_name] == -1).sum() / len(predictions[model_name])\n",
    "        \n",
    "        print(f\"False positive rates: {fp_rates}\")\n",
    "        print(f\"Detection rates: {detection_rates}\")\n",
    "        \n",
    "        # Weight heavily based on false positive rate\n",
    "        # Lower FP rate = higher weight\n",
    "        weights = {}\n",
    "        for name in fp_rates:\n",
    "            if fp_rates[name] < 0.01:\n",
    "                weights[name] = 1.0  # Excellent\n",
    "            elif fp_rates[name] < 0.1:\n",
    "                weights[name] = 0.5  # Good\n",
    "            elif fp_rates[name] < 0.5:\n",
    "                weights[name] = 0.1  # Poor\n",
    "            else:\n",
    "                weights[name] = 0.01  # Very poor\n",
    "        \n",
    "        # Normalize weights\n",
    "        total_weight = sum(weights.values())\n",
    "        if total_weight > 0:\n",
    "            self.ensemble_weights = {name: w/total_weight for name, w in weights.items()}\n",
    "        else:\n",
    "            # Fallback to default weights\n",
    "            self.ensemble_weights = {'isolation_forest': 0.8, 'one_class_svm': 0.2}\n",
    "        \n",
    "        print(f\"Optimized ensemble weights: {self.ensemble_weights}\")\n",
    "    \n",
    "    def test(self, test_data, use_ensemble=True):\n",
    "        \"\"\"Test ML models and compare with ground truth\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"TESTING PHASE - INVALID MESSAGE DETECTION\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Get ground truth invalid messages\n",
    "        invalid_messages = self.detect_invalid_messages(test_data)\n",
    "        print(f\"\\nGround truth: {len(invalid_messages)} invalid messages found\")\n",
    "        \n",
    "        # Prepare test data\n",
    "        test_df = self.preprocess_data(test_data)\n",
    "        features, nas_df = self.engineer_features_enhanced(test_df)\n",
    "        features_subset = features[self.feature_columns]\n",
    "        X_test = self.scaler.transform(features_subset)\n",
    "        \n",
    "        # Get true labels\n",
    "        y_true = np.zeros(len(nas_df))\n",
    "        for invalid_msg in invalid_messages:\n",
    "            y_true[invalid_msg['index']] = 1\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Test individual models\n",
    "        for model_name, model in self.trained_models.items():\n",
    "            predictions = model.predict(X_test)\n",
    "            scores = model.decision_function(X_test) if hasattr(model, 'decision_function') else model.score_samples(X_test)\n",
    "            \n",
    "            # Convert predictions\n",
    "            y_pred = (predictions == -1).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "            \n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            results[model_name] = {\n",
    "                'predictions': y_pred,\n",
    "                'scores': scores,\n",
    "                'metrics': {\n",
    "                    'true_positives': tp,\n",
    "                    'false_positives': fp,\n",
    "                    'false_negatives': fn,\n",
    "                    'true_negatives': tn,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1_score': f1\n",
    "                },\n",
    "                'nas_df': nas_df\n",
    "            }\n",
    "        \n",
    "        # Add enhanced ensemble results\n",
    "        if use_ensemble:\n",
    "            ensemble_predictions, ensemble_scores = self.ensemble_predict_with_confidence(X_test, features)\n",
    "            y_pred_ensemble = (ensemble_predictions == -1).astype(int)\n",
    "            \n",
    "            tp = np.sum((y_true == 1) & (y_pred_ensemble == 1))\n",
    "            fp = np.sum((y_true == 0) & (y_pred_ensemble == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred_ensemble == 0))\n",
    "            tn = np.sum((y_true == 0) & (y_pred_ensemble == 0))\n",
    "            \n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            results['ensemble'] = {\n",
    "                'predictions': y_pred_ensemble,\n",
    "                'scores': ensemble_scores,\n",
    "                'metrics': {\n",
    "                    'true_positives': tp,\n",
    "                    'false_positives': fp,\n",
    "                    'false_negatives': fn,\n",
    "                    'true_negatives': tn,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1_score': f1\n",
    "                },\n",
    "                'nas_df': nas_df\n",
    "            }\n",
    "        \n",
    "        return results, invalid_messages\n",
    "    \n",
    "    def print_metrics(self, results):\n",
    "        \"\"\"Print detailed metrics for each model\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"MODEL PERFORMANCE METRICS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for model_name, result in results.items():\n",
    "            metrics = result['metrics']\n",
    "            print(f\"\\n{model_name.upper()}:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"  True Positives:  {metrics['true_positives']}\")\n",
    "            print(f\"  False Positives: {metrics['false_positives']}\")\n",
    "            print(f\"  False Negatives: {metrics['false_negatives']}\")\n",
    "            print(f\"  True Negatives:  {metrics['true_negatives']}\")\n",
    "            print(f\"  Precision:       {metrics['precision']:.2%}\")\n",
    "            print(f\"  Recall:          {metrics['recall']:.2%}\")\n",
    "            print(f\"  F1-Score:        {metrics['f1_score']:.2%}\")\n",
    "    \n",
    "    def analyze_invalid_messages(self, test_data, invalid_messages):\n",
    "        \"\"\"Detailed analysis of detected invalid messages\"\"\"\n",
    "        if not invalid_messages:\n",
    "            print(\"\\n✓ No invalid messages to analyze\")\n",
    "            return None\n",
    "            \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"DETAILED INVALID MESSAGE ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        test_df = self.preprocess_data(test_data)\n",
    "        \n",
    "        print(f\"\\nFound {len(invalid_messages)} invalid message(s):\")\n",
    "        print(\"\\n\" + \"-\"*100)\n",
    "        \n",
    "        # Group by violation type\n",
    "        violation_types = defaultdict(int)\n",
    "        for msg in invalid_messages:\n",
    "            for violation in msg['violations']:\n",
    "                violation_types[violation] += 1\n",
    "        \n",
    "        print(\"\\nViolation Summary:\")\n",
    "        for violation, count in sorted(violation_types.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {violation}: {count} occurrences\")\n",
    "        \n",
    "        # Show detailed analysis for first 5 invalid messages\n",
    "        print(\"\\n\" + \"-\"*100)\n",
    "        print(\"\\nDetailed Analysis (first 5 messages):\")\n",
    "        \n",
    "        for i, invalid_msg in enumerate(invalid_messages[:5]):\n",
    "            print(f\"\\nINVALID MESSAGE #{i+1}\")\n",
    "            print(\"-\"*50)\n",
    "            \n",
    "            msg = test_df.iloc[invalid_msg['index']]\n",
    "            \n",
    "            print(f\"  Time:        {msg['Time']:.6f}s\")\n",
    "            print(f\"  Session:     {int(msg['AMF_UE_NGAP_ID'])}\")\n",
    "            print(f\"  Message Type: {int(msg['Type']) if not pd.isna(msg['Type']) else 'NaN'}\", end=\"\")\n",
    "            \n",
    "            msg_type_str = str(int(msg['Type'])) if not pd.isna(msg['Type']) else None\n",
    "            if msg_type_str in self.valid_5gmm_types:\n",
    "                print(f\" ({self.valid_5gmm_types[msg_type_str]})\")\n",
    "            else:\n",
    "                print(\" (UNKNOWN)\")\n",
    "            \n",
    "            print(f\"  Proc Code:   {int(msg['procedureCode']) if not pd.isna(msg['procedureCode']) else 'NaN'}\")\n",
    "            print(f\"  Sequence:    {int(msg['Seqn']) if not pd.isna(msg['Seqn']) else 'NaN'}\")\n",
    "            print(f\"  SecHdr:      {int(msg['SecHdr']) if not pd.isna(msg['SecHdr']) else 'NaN'}\")\n",
    "            print(f\"  EPD:         {int(msg['EPD']) if not pd.isna(msg['EPD']) else 'NaN'}\")\n",
    "            print(f\"  Spare:       {int(msg['spare']) if not pd.isna(msg['spare']) else 'NaN'}\")\n",
    "            print(f\"  Severity:    {invalid_msg['severity']}\")\n",
    "            \n",
    "            print(f\"\\n  Violations ({invalid_msg['violation_count']}):\")\n",
    "            for violation in invalid_msg['violations']:\n",
    "                print(f\"    ⚠️  {violation}\")\n",
    "        \n",
    "        return invalid_messages\n",
    "    \n",
    "    def visualize_anomalies(self, results, invalid_messages):\n",
    "        \"\"\"Create visualizations for invalid message detection results\"\"\"\n",
    "        n_models = len(results)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # 1. Detection comparison bar chart\n",
    "        ax1 = axes[0]\n",
    "        \n",
    "        normal_counts = []\n",
    "        invalid_counts = []\n",
    "        \n",
    "        for model_name, result in results.items():\n",
    "            predictions = result['predictions']\n",
    "            normal = np.sum(predictions == 0)\n",
    "            invalid = np.sum(predictions == 1)\n",
    "            \n",
    "            normal_counts.append(normal)\n",
    "            invalid_counts.append(invalid)\n",
    "        \n",
    "        model_names = list(results.keys())\n",
    "        x = np.arange(len(model_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax1.bar(x - width/2, normal_counts, width, label='Valid Messages', color='lightgreen')\n",
    "        bars2 = ax1.bar(x + width/2, invalid_counts, width, label='Invalid Messages', color='lightcoral')\n",
    "        \n",
    "        # Add count labels\n",
    "        for i, (normal, invalid) in enumerate(zip(normal_counts, invalid_counts)):\n",
    "            ax1.text(i - width/2, normal + 0.5, str(normal), ha='center', va='bottom')\n",
    "            ax1.text(i + width/2, invalid + 0.5, str(invalid), ha='center', va='bottom')\n",
    "        \n",
    "        ax1.set_xlabel('Models')\n",
    "        ax1.set_ylabel('Number of Messages')\n",
    "        ax1.set_title('Valid vs Invalid Message Detection by Model')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(model_names, rotation=15)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # 2. Violation type distribution\n",
    "        ax2 = axes[1]\n",
    "        \n",
    "        violation_types = defaultdict(int)\n",
    "        for msg in invalid_messages:\n",
    "            for violation in msg['violations']:\n",
    "                # Simplify violation descriptions for plotting\n",
    "                if \"Invalid message type\" in violation:\n",
    "                    violation_types[\"Invalid Message Type\"] += 1\n",
    "                elif \"Invalid EPD\" in violation:\n",
    "                    violation_types[\"Invalid EPD\"] += 1\n",
    "                elif \"Invalid security header\" in violation:\n",
    "                    violation_types[\"Invalid Security Header\"] += 1\n",
    "                elif \"Invalid sequence number\" in violation:\n",
    "                    violation_types[\"Invalid Sequence Number\"] += 1\n",
    "                elif \"Invalid spare field\" in violation:\n",
    "                    violation_types[\"Invalid Spare Field\"] += 1\n",
    "        \n",
    "        if violation_types:\n",
    "            violations = list(violation_types.keys())\n",
    "            counts = list(violation_types.values())\n",
    "            \n",
    "            y_pos = np.arange(len(violations))\n",
    "            ax2.barh(y_pos, counts, color='orange')\n",
    "            ax2.set_yticks(y_pos)\n",
    "            ax2.set_yticklabels(violations)\n",
    "            ax2.set_xlabel('Count')\n",
    "            ax2.set_title('Distribution of Violation Types')\n",
    "            ax2.grid(True, alpha=0.3, axis='x')\n",
    "            \n",
    "            # Add count labels\n",
    "            for i, count in enumerate(counts):\n",
    "                ax2.text(count + 0.1, i, str(count), va='center')\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'No violations detected', \n",
    "                    ha='center', va='center', transform=ax2.transAxes)\n",
    "            ax2.set_title('Distribution of Violation Types')\n",
    "        \n",
    "        # 3. Performance metrics comparison\n",
    "        ax3 = axes[2]\n",
    "        \n",
    "        metrics_data = []\n",
    "        for model_name, result in results.items():\n",
    "            m = result['metrics']\n",
    "            metrics_data.append({\n",
    "                'model': model_name,\n",
    "                'precision': m['precision'] * 100,\n",
    "                'recall': m['recall'] * 100,\n",
    "                'f1_score': m['f1_score'] * 100\n",
    "            })\n",
    "        \n",
    "        y_positions = np.arange(len(model_names))\n",
    "        \n",
    "        for i, data in enumerate(metrics_data):\n",
    "            ax3.scatter(data['precision'], i, s=100, label='Precision' if i == 0 else '', \n",
    "                       color='blue', marker='o')\n",
    "            ax3.scatter(data['recall'], i, s=100, label='Recall' if i == 0 else '', \n",
    "                       color='green', marker='s')\n",
    "            ax3.scatter(data['f1_score'], i, s=100, label='F1-Score' if i == 0 else '', \n",
    "                       color='red', marker='^')\n",
    "            \n",
    "            # Add value labels\n",
    "            ax3.text(data['precision'] + 1, i, f\"{data['precision']:.1f}%\", \n",
    "                    va='center', fontsize=9, color='blue')\n",
    "            ax3.text(data['recall'] + 1, i + 0.1, f\"{data['recall']:.1f}%\", \n",
    "                    va='center', fontsize=9, color='green')\n",
    "            ax3.text(data['f1_score'] + 1, i - 0.1, f\"{data['f1_score']:.1f}%\", \n",
    "                    va='center', fontsize=9, color='red')\n",
    "        \n",
    "        ax3.set_yticks(y_positions)\n",
    "        ax3.set_yticklabels(model_names)\n",
    "        ax3.set_xlabel('Performance (%)')\n",
    "        ax3.set_title('Model Performance Metrics')\n",
    "        ax3.set_xlim(-5, 110)\n",
    "        ax3.legend(loc='lower right')\n",
    "        ax3.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Add summary\n",
    "        fig.suptitle(f'Invalid NAS Message Detection Analysis - {len(invalid_messages)} Invalid Message(s) Found', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('invalid_message_detection_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"\\n✓ Visualizations saved as 'invalid_message_detection_analysis.png'\")\n",
    "        plt.show()\n",
    "    \n",
    "    def save_models(self, filepath='nas_invalid_message_models.pkl'):\n",
    "        \"\"\"Save trained models and parameters\"\"\"\n",
    "        model_data = {\n",
    "            'models': self.trained_models,\n",
    "            'scaler': self.scaler,\n",
    "            'feature_columns': self.feature_columns,\n",
    "            'ensemble_weights': self.ensemble_weights,\n",
    "            'optimal_threshold': self.optimal_threshold,\n",
    "            'contamination_rate': self.contamination_rate,\n",
    "            'valid_5gmm_types': self.valid_5gmm_types,\n",
    "            'confidence_threshold': self.confidence_threshold,\n",
    "            'rule_based_weight': self.rule_based_weight,\n",
    "            'ml_based_weight': self.ml_based_weight\n",
    "        }\n",
    "        joblib.dump(model_data, filepath)\n",
    "        print(f\"\\n✓ Models saved to {filepath}\")\n",
    "    \n",
    "    def load_models(self, filepath='nas_invalid_message_models.pkl'):\n",
    "        \"\"\"Load trained models and parameters\"\"\"\n",
    "        model_data = joblib.load(filepath)\n",
    "        self.trained_models = model_data['models']\n",
    "        self.scaler = model_data['scaler']\n",
    "        self.feature_columns = model_data['feature_columns']\n",
    "        self.ensemble_weights = model_data.get('ensemble_weights', {'isolation_forest': 0.5, 'one_class_svm': 0.5})\n",
    "        self.optimal_threshold = model_data.get('optimal_threshold', None)\n",
    "        self.contamination_rate = model_data.get('contamination_rate', 0.01)\n",
    "        self.valid_5gmm_types = model_data.get('valid_5gmm_types', self.valid_5gmm_types)\n",
    "        self.confidence_threshold = model_data.get('confidence_threshold', 0.8)\n",
    "        self.rule_based_weight = model_data.get('rule_based_weight', 0.6)\n",
    "        self.ml_based_weight = model_data.get('ml_based_weight', 0.4)\n",
    "        print(f\"\\n✓ Models loaded from {filepath}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize detector\n",
    "    detector = EnhancedNASInvalidMessageDetector()\n",
    "    \n",
    "    # Train on clean data\n",
    "    print(\"Loading training data...\")\n",
    "    train_data = pd.read_csv(\"BenignData.csv\", dtype=str, sep=\";\")\n",
    "    print(f\"Training data shape: {train_data.shape}\")\n",
    "    \n",
    "    print(\"\\nStarting training for invalid message detection...\")\n",
    "    detector.train(train_data, optimize_params=True)\n",
    "    \n",
    "    # Save models\n",
    "    detector.save_models('nas_invalid_message_models.pkl')\n",
    "    \n",
    "    # Test on potentially contaminated data\n",
    "    print(\"\\nLoading test data...\")\n",
    "    test_data = pd.read_csv(\"InvalidheaderTest.csv\", dtype=str, sep=\";\")\n",
    "    print(f\"Test data shape: {test_data.shape}\")\n",
    "    \n",
    "    results, invalid_messages = detector.test(test_data, use_ensemble=True)\n",
    "    \n",
    "    # Analyze invalid messages\n",
    "    detector.analyze_invalid_messages(test_data, invalid_messages)\n",
    "    \n",
    "    # Print metrics\n",
    "    detector.print_metrics(results)\n",
    "    \n",
    "    # Create visualizations\n",
    "    detector.visualize_anomalies(results, invalid_messages)\n",
    "    \n",
    "    # Demonstrate model loading\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DEMONSTRATING MODEL LOAD\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    new_detector = EnhancedNASInvalidMessageDetector()\n",
    "    new_detector.load_models('nas_invalid_message_models.pkl')\n",
    "    \n",
    "    # Test with loaded models\n",
    "    results2, _ = new_detector.test(test_data, use_ensemble=True)\n",
    "    print(\"\\n✓ Loaded models produce consistent results!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"INVALID MESSAGE DETECTION COMPLETE\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04498c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
